{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Breast_Cancer_Prediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGj4DCEnugoN"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "def init():\n",
        "    \n",
        "    df=pd.read_csv(\"../Data/data.csv\")\n",
        "    \n",
        "    \n",
        "    #Dropping the 'id' column from the dataset\n",
        "    df=df.drop(\"id\",1)\n",
        "    df=df.drop(\"Unnamed: 32\",1)\n",
        "    \n",
        "    #Mapping M to 1 and B to 0 in the output Label DataFrame\n",
        "    df['diagnosis']=df['diagnosis'].map({'M':1,'B':0})\n",
        "    \n",
        "    \n",
        "    #Split Data into training and test (70% and 30%)\n",
        "    train, test = train_test_split(df, test_size = 0.3, random_state=1)\n",
        "        \n",
        "    \n",
        "    #Training Data\n",
        "    train_x=train.loc[:,'radius_mean' : 'fractal_dimension_worst']\n",
        "    train_y=train.loc[:,['diagnosis']]\n",
        "    \n",
        "    #Testing Data\n",
        "    test_x=test.loc[:,'radius_mean' : 'fractal_dimension_worst']\n",
        "    test_y=test.loc[:,['diagnosis']]\n",
        "    \n",
        "    #Converting Traing and Test Data to numpy array\n",
        "    train_x=np.asarray(train_x)\n",
        "    train_y=np.asarray(train_y)\n",
        "    test_x=np.asarray(test_x)\n",
        "    test_y=np.asarray(test_y)\n",
        "    \n",
        "    #Calling the model function to train a Logistic Regression Model on Training Data\n",
        "    d= model(train_x.T, train_y.T, num_of_iterations=10000, alpha=0.000001)\n",
        "    \n",
        "        \n",
        "    costs=d[\"costs\"]\n",
        "    w=d[\"w\"]\n",
        "    b=d[\"b\"]\n",
        "    \n",
        "    #Drawing the plot between cost and number of iterations\n",
        "    plt.plot(costs)\n",
        "    plt.title(\"Cost vs #Iterations\")\n",
        "    plt.xlabel(\"Number of Iterations ( * 10)\")\n",
        "    plt.ylabel(\"Cost\")\n",
        "    \n",
        "    \n",
        "    #Now, calculating the accuracy on Training and Test Data\n",
        "    Y_prediction_train = predict(train_x.T, w, b)\n",
        "    Y_prediction_test = predict(test_x.T, w, b)\n",
        "    \n",
        "    \n",
        "    \n",
        "    print(\"\\nTrain accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - train_y.T)) * 100))\n",
        "    \n",
        "    print(\"\\nTest accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - test_y.T)) * 100))\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "#Function to initialize the weights and bias\n",
        "def initialize(m):\n",
        "    \n",
        "    w = np.zeros((m,1))\n",
        "    b = 0\n",
        "    \n",
        "    return w , b\n",
        "    \n",
        "#Function to calculate sigmoid of x    \n",
        "def sigmoid(X):\n",
        "    return 1/(1 + np.exp(- X))    \n",
        "\n",
        "\n",
        "#Function for doing forward and back propogation\n",
        "def propogate(X, Y, w, b):\n",
        "    \n",
        "    m = X.shape[1] #Number of training examples\n",
        "\n",
        "    #Forward Propogation, calculating the cost\n",
        "    Z = np.dot(w.T, X) + b;    \n",
        "    A = sigmoid(Z)\n",
        "    cost= -(1/m) * np.sum(Y * np.log(A) + (1-Y) * np.log(1-A))\n",
        "    \n",
        "    #Back Propogation , calculating the gradients\n",
        "    dw = (1/m)* np.dot(X, (A-Y).T)\n",
        "    db = (1/m)* np.sum(A-Y)\n",
        "    \n",
        "    grads= {\"dw\" : dw, \"db\" : db}\n",
        "    \n",
        "    return grads, cost\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "#Function for performing Grdient Descent\n",
        "def optimize(X, Y, w, b, num_of_iterations, alpha):\n",
        "    \n",
        "    costs=[] \n",
        "    \n",
        "    for i in range(num_of_iterations):\n",
        " \n",
        "        grads, cost = propogate(X, Y, w, b)\n",
        "        \n",
        "        dw = grads[\"dw\"]\n",
        "        db = grads[\"db\"]\n",
        "        \n",
        "        w = w - alpha * dw\n",
        "        b = b - alpha * db\n",
        "        \n",
        "        #Storing tthe cost at interval of every 10 iterations\n",
        "        if i% 10 == 0:\n",
        "            costs.append(cost)\n",
        "            print(\"cost after %i iteration : %f\" % (i, cost))\n",
        "            \n",
        "            \n",
        "    parameters = {\"w\":w, \"b\":b}\n",
        "    grads = {\"dw\":dw, \"db\":db}\n",
        "    \n",
        "    \n",
        "    return parameters, grads, costs\n",
        "\n",
        "\n",
        "#Function for doing the predictions on the data set (mapping probabilities to 0 or 1)\n",
        "def predict(X, w, b):\n",
        "    \n",
        "    m = X.shape[1] #Number of training examples\n",
        "    \n",
        "    y_prediction =  np.zeros((1,m))\n",
        "    \n",
        "    w = w.reshape(X.shape[0], 1)\n",
        "    \n",
        "    A=sigmoid(np.dot(w.T, X)+b)\n",
        "    \n",
        "    \n",
        "    for i in range(A.shape[1]):\n",
        "        \n",
        "        if(A[0,i]<0.5):\n",
        "            y_prediction[0,i]=0\n",
        "        else:\n",
        "            y_prediction[0,i]=1\n",
        "            \n",
        "    \n",
        "    return y_prediction\n",
        "\n",
        "\n",
        "#Function for calculating the Logistic Regression Model\n",
        "def model(Xtrain, Ytrain, num_of_iterations, alpha):\n",
        "    \n",
        "    dim = Xtrain.shape[0] #Number of features\n",
        "    \n",
        "    w,b = initialize(dim)\n",
        "    \n",
        "    parameters, grads, costs = optimize(Xtrain, Ytrain, w, b, num_of_iterations, alpha) \n",
        "    \n",
        "    w = parameters[\"w\"]\n",
        "    b = parameters[\"b\"]\n",
        "        \n",
        "    \n",
        "    d={\"w\":w, \"b\":b, \"costs\": costs}\n",
        "    \n",
        "    return d\n",
        "    \n",
        "\n",
        "\n",
        "#Calling the init function to start the program\n",
        "init()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}